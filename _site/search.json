[
  {
    "objectID": "likelihood.html",
    "href": "likelihood.html",
    "title": "Likelihood",
    "section": "",
    "text": "Implementing in pomp\nCreating a pomp object\nComputing likelihood\n\n\noptions(warning = FALSE)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nlibrary(readr)\nlibrary(iterators)\nlibrary(pomp)\nlibrary(ggplot2)\nlibrary(foreach)\nlibrary(doParallel)\n\nLoading required package: parallel"
  },
  {
    "objectID": "likelihood.html#summary",
    "href": "likelihood.html#summary",
    "title": "Likelihood",
    "section": "",
    "text": "Implementing in pomp\nCreating a pomp object\nComputing likelihood\n\n\noptions(warning = FALSE)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nlibrary(readr)\nlibrary(iterators)\nlibrary(pomp)\nlibrary(ggplot2)\nlibrary(foreach)\nlibrary(doParallel)\n\nLoading required package: parallel"
  },
  {
    "objectID": "likelihood.html#recap-a-stochastic-sir-model-in-the-pomp-framework",
    "href": "likelihood.html#recap-a-stochastic-sir-model-in-the-pomp-framework",
    "title": "Likelihood",
    "section": "Recap: A stochastic SIR model in the POMP framework",
    "text": "Recap: A stochastic SIR model in the POMP framework\nWe define the state process as a stochastic SIR model, \\(X_t=(S_t, I_t, R_t, D_t)\\) where \\(D_t\\) is the weekly cumulative diagnoses, getting reset to 0 every 7 days. The number of infections \\(\\Delta N_{SI}\\) and recoveries \\(\\Delta N_{IR}\\) are random variables, following Binomial distributions:\n\\[\\begin{aligned}\n  \\Delta N_{SI} &\\sim \\mathrm{Binomial}\\left(S, 1-e^{-\\beta\\frac{I}{N}\\Delta t}\\right) \\\\\n  \\Delta N_{IR} &\\sim \\mathrm{Binomial}\\left(I, 1-e^{-\\gamma \\Delta t}\\right)\n\\end{aligned}\\]\nwhere \\(\\beta\\) is the transmission rate and \\(\\gamma\\) is the recovery rate.\nWe define a weekly measurement model which follows a Negative Binomial distribution with mean \\(\\rho D_t\\) and the dispersion parameter \\(k\\):\n\\[\n\\textrm{reports}_t \\sim \\textrm{NegBin}(\\rho D_t, k),\n\\]\nwhere \\(\\rho\\) is the reporting ratio and \\(0 \\leq \\rho \\leq 1\\) ."
  },
  {
    "objectID": "likelihood.html#implementing-the-sir-model-in-pomp-package",
    "href": "likelihood.html#implementing-the-sir-model-in-pomp-package",
    "title": "Likelihood",
    "section": "Implementing the SIR model in pomp package",
    "text": "Implementing the SIR model in pomp package\n\nExample: the Consett measles outbreak\nWe first download the data and take a look at them:\n\nread_csv(paste0(\"https://kingaa.github.io/sbied/stochsim/\", \n  \"Measles_Consett_1948.csv\")) |&gt;\n  select(week,reports=cases) -&gt; dat_meas\n\nRows: 53 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): week, cases\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat_meas |&gt; head()\n\n# A tibble: 6 × 2\n   week reports\n  &lt;dbl&gt;   &lt;dbl&gt;\n1     1       0\n2     2       0\n3     3       2\n4     4       0\n5     5       3\n6     6       0\n\ndat_meas |&gt; summary()\n\n      week       reports     \n Min.   : 1   Min.   : 0.00  \n 1st Qu.:14   1st Qu.: 0.00  \n Median :27   Median : 1.00  \n Mean   :27   Mean   : 9.83  \n 3rd Qu.:40   3rd Qu.: 7.00  \n Max.   :53   Max.   :75.00  \n\n\nand visualize:\n\ndat_meas |&gt;\n  ggplot(aes(x=week, y=reports)) +\n  geom_line() +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nA stochastic SIR model for measles in pomp\nTo accelerate the computation, we would like to code the model in C/C++ using C snippets in pomp. Now we can have our **one-step transition** function:\n\nsird_step &lt;- Csnippet(\"\n  double N = S + I + R;\n  double dN_SI = rbinom(S, 1-exp(-Beta*I/N*dt));\n  double dN_IR = rbinom(I, 1-exp(-gamma*dt));\n  S -= dN_SI;\n  I += dN_SI - dN_IR;\n  R += dN_IR;\n  D += dN_IR;\n\")\n\nand the initialization and measurement model:\n\nsird_rinit &lt;- Csnippet(\"\n  S = S0;\n  I = I0;\n  R = R0;\n  D = 0;\n\")\n\nsird_dmeas &lt;- Csnippet(\"\n  lik = dnbinom_mu(reports, k, rho*D, give_log);\n\")\n\nsird_rmeas &lt;- Csnippet(\"\n  reports = rnbinom_mu(k, rho*D);\n\")\n\nNow we can put the model together in pomp and simulate the model dynamics:\n\ndat_meas |&gt;\n  pomp(\n    times=\"week\",\n    t0=0,\n    rprocess = euler(sird_step, delta.t = 1/7),\n    rinit = sird_rinit,\n    rmeasure = sird_rmeas,\n    dmeasure = sird_dmeas,\n    accumvars = \"D\",\n    statenames = c(\"S\",\"I\",\"R\",\"D\"),\n    paramnames = c(\"Beta\",\"gamma\",\"rho\",\"k\",\"S0\",\"I0\",\"R0\")\n  ) -&gt; sird_measle\n\nAfter getting the components in place in pomp, we can simulate the dynamics with some parameters from literature or anything you want:\n\nsird_measle |&gt;\n  simulate(\n    params = c(\n      Beta = 7.5, gamma = .5, rho = .5, k = 10,\n      S0 = 1140, I0 = 1, R0 = 36860\n    ),\n    nsim = 100,\n    format = \"data.frame\",\n    include.data = TRUE\n  ) -&gt; sims_measle\n\nsims_measle |&gt; head()\n\n  week  .id reports  S  I  R  D\n1    1 data       0 NA NA NA NA\n2    2 data       0 NA NA NA NA\n3    3 data       2 NA NA NA NA\n4    4 data       0 NA NA NA NA\n5    5 data       3 NA NA NA NA\n6    6 data       0 NA NA NA NA\n\nsummary(sims_measle)\n\n      week         .id          reports              S              I          \n Min.   : 1   data   :  53   Min.   : 0.0000   Min.   :1132   Min.   :0.00000  \n 1st Qu.:14   1      :  53   1st Qu.: 0.0000   1st Qu.:1139   1st Qu.:0.00000  \n Median :27   2      :  53   Median : 0.0000   Median :1140   Median :0.00000  \n Mean   :27   3      :  53   Mean   : 0.1128   Mean   :1139   Mean   :0.05585  \n 3rd Qu.:40   4      :  53   3rd Qu.: 0.0000   3rd Qu.:1140   3rd Qu.:0.00000  \n Max.   :53   5      :  53   Max.   :75.0000   Max.   :1140   Max.   :6.00000  \n              (Other):5035                     NA's   :53     NA's   :53       \n       R               D          \n Min.   :36860   Min.   :0.00000  \n 1st Qu.:36861   1st Qu.:0.00000  \n Median :36861   Median :0.00000  \n Mean   :36862   Mean   :0.03415  \n 3rd Qu.:36862   3rd Qu.:0.00000  \n Max.   :36869   Max.   :6.00000  \n NA's   :53      NA's   :53       \n\nsims_measle |&gt;\n  ggplot(aes(x=week, y=reports, group=.id,color=(.id==\"data\"))) +\n  geom_line() +\n  guides(color=\"none\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nObviously, the proposed set of parameters doesn’t seem to be right. We can play around with the parameters to see whether we can obtain better simulations.\n\n\nA SEIR model?"
  },
  {
    "objectID": "likelihood.html#likelihood-based-inference-for-pomp-models",
    "href": "likelihood.html#likelihood-based-inference-for-pomp-models",
    "title": "Likelihood",
    "section": "Likelihood-based inference for POMP models",
    "text": "Likelihood-based inference for POMP models\n\nRecap: the POMP structure\nThe POMP model consist of two components: the state process \\(X_t\\) and the observations \\(Y_t\\). The state process is Markovian, and transitions between states are driven by the process model, where we code it as sird_step; the observations are derived from the states, governed by a measurement model which we code in sird_rmeas for simulation and sird_dmeas for density computation.\n\n\n\nPOMP schematic. In previous example, we define the states as \\(X_t = (S_t, I_t, R_t, D_t)\\) and the process model as the SIR dynamics; the observations are the weekly reported cases and the measurement model is defined as a negative binomial distribution.\n\n\n\n\nLikelihood of the stochastic SIR model for measles\nIt will be straight-forward to compute the log-likelihood of \\(\\rho\\) and \\(k\\) of the data (i.e., weekly reports), given the underlying weekly cumulative diagnoses:\n\\[\n\\ell(\\rho, k) = \\sum_{w=1}^W\\, \\log p(report_w \\vert D_w, \\rho, k),\n\\]\nwhere \\(W\\) is the total number of reporting weeks and \\(p\\) is the probability mass function of Negative Binomial distribution. Unfortunately, we don’t have any knowledge of \\(D_t\\) because it is part of the unobserved underlying stochastic SIR dynamics, which we can simulate.\nNow, let’s keep in mind the observations \\(Y_w\\) is the weekly reported cases \\(\\mathrm{report}_w\\), and the unobserved states \\(X_t = (S_t, I_t, R_t, D_t)\\). We denote the density of the process model as \\(f_{X_w\\vert X_{w-1}}\\), the density of the measurement model as \\(f_{Y_w\\vert X_w}\\), the initialization density \\(f_{X_0}\\), and the set of parameters \\(\\theta = (\\beta, \\gamma, \\rho, k, S_0, I_0, R_0)\\). The likelihood for a POMP model takes the form of an integral:\n\\[\n\\mathcal{L}(\\theta) = \\int f_{X_0}(x_0;\\theta)\\, \\prod_{w=1}^W f_{Y_w\\vert X_w} (y_w^\\ast\\vert x_w;\\theta)\\,f_{X_w\\vert X_{w-1}}(x_w \\vert x_w;\\theta) d x_{0:W},\n\\]\nwhere \\(y_w^\\ast\\) is the data (reported cases) in \\(w\\)-th week.\n\n\nMonte Carlo likelihood by direct simulation\nThe intuitive idea is to simulate the sequence of states at each week, denoted as \\(X_{0:W}\\), and then the likelihood is given by\n\\[\\begin{aligned}\n  y &= \\int \\prod_{w=1}^W\\,f_{Y_w\\vert X_w}(y_w^\\ast\\vert x_w;\\theta) f_{X_{0:W}}(x_{0:w};\\theta) dx_{0:W} \\\\\n    &= \\mathbb{E}\\left[\\prod_{w=1}^W\\,f_{Y_w\\vert X_w}(y_w^\\ast\\vert x_w;\\theta)\\right],\n\\end{aligned}\\]\nwhere the expectation is taken with \\(X_{0:W}\\sim f_{X_{0:W}}(x_{0:W};\\theta)\\).\nUsing a law of large numbers, we can simulate a large set (\\(J\\)) of sequences \\(\\{X_{0:W}^j, j=1,\\dots,J\\}\\) and take the average of this Monte Carlo sample, which converges to the expectation: \\[\n\\mathcal{L}(\\theta) \\approx \\frac{1}{J}\\sum_{j=1}^J\\,\\prod_{w=1}^W\\,f_{Y_w\\vert X_w}(y_w^\\ast\\vert x_w;\\theta).\n\\]\nHowever, things are not that straight-forward and intuitive because this naive approach scales poorly with dimension, in other words, it requires a Monte Carlo effort (\\(J\\)) that scales exponentially with the length of the time series, and so is unfeasible on anything but a short data set. Another aspect to consider is that, the underlying process is stochastic, the simulations therefore diverge mostly, many of which don’t align with the observed data thus are useless for parameter estimation.\n\n\nSequential Monte Carlo: the particle filter\nThe idea of Sequential Monte Carlo (SMC) is that, instead of computing and evaluating the whole sequence of states at once, we evaluate the state at every time step. At current state, we evaluate whether it aligns with the data: if yes, then we keep it and continue to simulate the next state; if no, we just drop it. This procedure is called “importance sampling”.\nWe therefore can factorize the likelihood:\n\\[\\begin{aligned}\n  \\mathcal{L}(\\theta) &= f_{Y_{1:W}}(y_{1:W}^\\ast;\\theta) = \\prod_{w=1}^W\\,f_{Y_w\\vert Y_{1:w-1}}(y_w^\\ast\\vert y^\\ast_{1:w-1};\\theta) \\\\\n  &= \\prod_{w=1}^W\\,\\int f_{Y_w\\vert X_w}(y_w^\\ast \\vert x_w;\\theta) f_{X_w\\vert Y_{1:w-1}}(x_w\\vert y_{1:w-1}^\\ast) d x_w,\n\\end{aligned}\\]\nwhere obviously \\(f_{X_1\\vert Y_{1:0}} = f_{X_1}\\). With the Markov property and the Baye’s theorem, we can break the factorization into two steps, predition and filtering:\n\nthe prediction formula, gives the prediction at time \\(t_w\\) conditioned on the filtering distribution at time \\(t_{w-1}\\):\n\n\\[\\begin{aligned}\n  & f_{X_w\\vert Y_{1:w-1}}(x_w\\vert y_{1:w-1}^\\ast;\\theta) \\\\\n  & \\qquad = \\int f_{X_w\\vert X_{w-1}}(x_w\\vert x_{w-1};\\theta) f_{X_{w-1}\\vert Y_{1:w-1}} (x_{w-1}\\vert y_{1:w-1}^\\ast) d x_{w-1};\n\\end{aligned}\\]\n\nthe filtering formula, gives the filtering distribution at time \\(t_w\\) using the prediction distribution at time \\(t_w\\):\n\n\\[\\begin{aligned}\n  & f_{X_w\\vert Y_{1:w}} (x_w\\vert y_{1:w}^\\ast;\\theta) \\\\\n  & \\qquad = f_{X_w\\vert Y_w, Y_{1:w-1}} (x_w \\vert y_w^\\ast, y_{1:w-1}^\\ast;\\theta) \\\\\n  & \\qquad = \\dfrac{f_{Y_w\\vert X_w}(y_w^\\ast\\vert x_w;\\theta)\\,f_{X_w\\vert Y_{1:w-1}}(x_w\\vert y_{1:w-1}^\\ast;\\theta)}{\\int f_{Y_w\\vert X_w} (y_{w}^\\ast\\vert u_w;\\theta)\\,f_{X_w\\vert Y_{1:w-1}}(u_w\\vert y_{1:w-1}^\\ast;\\theta)} d u_w.\n\\end{aligned}\\]\nWe now can have a one-step particle filtering as follows:\n\nSuppose we have a set of \\(J\\) samples for the state \\(X_{w-1}^F, j=1,\\dots,J\\) drawn from the filtering distribution at time \\(t_{w-1}\\);\nWe then can obtain a set of samples \\(X_{w, j}^P\\) drawn from the prediction distribution at time \\(t_w\\) by simulating the process model: \\[\nX_{w,j}^P \\sim \\mathrm{process}(X_{w-1}^F,\\theta), j=1,\\dots,J;\n\\]\nGiven the set of samples for the state at time \\(t_w\\), we can obtain the filtering distribution by resampling from this set \\(\\{X_{w,j}^P, j=1,\\dots,J\\}\\) with weights (the density of the measurement model): \\[\n\\nu_{w,j} = f_{Y_w\\vert X_w}(y_w^\\ast\\vert X_{w,j}^P;\\theta);\n\\]\nThe Monte Carlo principle (law of large numbers) gives the approximated likelihood: \\[\n\\hat{\\mathcal{L}}_w(\\theta) \\approx \\frac{1}{J} \\sum_j f_{Y_w\\vert X_w} (y_{w}^\\ast \\vert X_{w,j}^P;\\theta)\n\\] since \\(X_{w,j}^P\\) is approximately a draw from \\(f_{X_w\\vert Y_{1:w-1}} (x_w \\vert y_{1:w-1}^\\ast;\\theta)\\);\n\nThen we can iterate through the end of the time and the approximated full log-likelihood is given by: \\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta) = \\sum_w \\log \\mathcal{L}_{w}(\\theta) \\approx \\sum_w \\hat{\\mathcal{L}}_{w}(\\theta).\n\\]"
  },
  {
    "objectID": "likelihood.html#paticle-filtering-in-pomp",
    "href": "likelihood.html#paticle-filtering-in-pomp",
    "title": "Likelihood",
    "section": "Paticle filtering in pomp",
    "text": "Paticle filtering in pomp\nWe can now try to compute the log-likelihood in pomp using the function pfilter with \\(J=5000\\):\n\nsird_measle |&gt;\n  pfilter(\n    params = c(\n      Beta = 7.5, gamma = .5, rho = .5, k = 10,\n      S0 = 1140, I0 = 1, R0 = 36860\n    ),\n    Np=5000\n  ) -&gt; pf\nlogLik(pf)\n\n[1] -Inf\n\n\nWe can try another set of parameters:\n\nsird_measle |&gt;\n  pfilter(\n    params = c(\n      Beta = 15, gamma = .5, rho = .5, k = 10,\n      S0 = 2280, I0 = 1, R0 = 35720\n    ),\n    Np=5000\n  ) |&gt;\n  logLik()\n\n[1] -135.4309\n\n\nUsing parallel computation, we can see the average log-likelihood and the variation in log-likelihoods:\n\nregisterDoParallel(cores=detectCores()-1)\nforeach (\n  i=1:10, .combine=c, .options.future=list(seed=652643293)\n  ) %dopar% {\n  sird_measle |&gt;\n  pfilter(\n    params = c(\n      Beta = 15, gamma = .5, rho = .5, k = 10,\n      S0 = 2280, I0 = 1, R0 = 35720\n    ),\n    Np=5000\n  )\n} -&gt; pf\nlogLik(pf) -&gt; ll\nlogmeanexp(ll,se=TRUE)\n\n         est           se \n-132.9091409    0.2954949"
  },
  {
    "objectID": "likelihood.html#slice-likelihood-changing-one-specific-parameter",
    "href": "likelihood.html#slice-likelihood-changing-one-specific-parameter",
    "title": "Likelihood",
    "section": "Slice likelihood: changing one specific parameter",
    "text": "Slice likelihood: changing one specific parameter\n\nsird_measle |&gt;\n  pomp(\n    params =  c(\n      Beta = 15, gamma = .5, rho = .5, k = 10,\n      S0 = 2280, I0 = 1, R0 = 35720\n    )\n  ) -&gt; sird_measle\n\nslice_design(\n  center=coef(sird_measle),\n  Beta = rep(seq(from=5,to=30,length=40),each=3),\n  gamma = rep(seq(from=0.2,to=2,length=40),each=3)\n) -&gt; params_slice\n\nhead(params_slice)\n\n      Beta gamma rho  k   S0 I0    R0 slice\n1 5.000000   0.5 0.5 10 2280  1 35720  Beta\n2 5.000000   0.5 0.5 10 2280  1 35720  Beta\n3 5.000000   0.5 0.5 10 2280  1 35720  Beta\n4 5.641026   0.5 0.5 10 2280  1 35720  Beta\n5 5.641026   0.5 0.5 10 2280  1 35720  Beta\n6 5.641026   0.5 0.5 10 2280  1 35720  Beta\n\nsummary(params_slice)\n\n      Beta           gamma            rho            k            S0      \n Min.   : 5.00   Min.   :0.200   Min.   :0.5   Min.   :10   Min.   :2280  \n 1st Qu.:15.00   1st Qu.:0.500   1st Qu.:0.5   1st Qu.:10   1st Qu.:2280  \n Median :15.00   Median :0.500   Median :0.5   Median :10   Median :2280  \n Mean   :16.25   Mean   :0.800   Mean   :0.5   Mean   :10   Mean   :2280  \n 3rd Qu.:17.34   3rd Qu.:1.088   3rd Qu.:0.5   3rd Qu.:10   3rd Qu.:2280  \n Max.   :30.00   Max.   :2.000   Max.   :0.5   Max.   :10   Max.   :2280  \n       I0          R0          slice    \n Min.   :1   Min.   :35720   Beta :120  \n 1st Qu.:1   1st Qu.:35720   gamma:120  \n Median :1   Median :35720              \n Mean   :1   Mean   :35720              \n 3rd Qu.:1   3rd Qu.:35720              \n Max.   :1   Max.   :35720              \n\n\nNow we can run the computations of likelihood at different combinations of parameters and visualize:\n\nforeach (\n  theta=iter(params_slice,\"row\"), .combine=rbind, .options.future=list(seed=108028909)\n  ) %dopar% {\n    sird_measle |&gt; pfilter(params=theta,Np=5000) -&gt; pf\n    theta$loglik &lt;- logLik(pf)\n    theta\n} -&gt; llks_slice\n\nsummary(llks_slice)\n\n      Beta           gamma            rho            k            S0      \n Min.   : 5.00   Min.   :0.200   Min.   :0.5   Min.   :10   Min.   :2280  \n 1st Qu.:15.00   1st Qu.:0.500   1st Qu.:0.5   1st Qu.:10   1st Qu.:2280  \n Median :15.00   Median :0.500   Median :0.5   Median :10   Median :2280  \n Mean   :16.25   Mean   :0.800   Mean   :0.5   Mean   :10   Mean   :2280  \n 3rd Qu.:17.34   3rd Qu.:1.088   3rd Qu.:0.5   3rd Qu.:10   3rd Qu.:2280  \n Max.   :30.00   Max.   :2.000   Max.   :0.5   Max.   :10   Max.   :2280  \n       I0          R0          slice         loglik      \n Min.   :1   Min.   :35720   Beta :120   Min.   :-483.5  \n 1st Qu.:1   1st Qu.:35720   gamma:120   1st Qu.:-174.7  \n Median :1   Median :35720               Median :-135.5  \n Mean   :1   Mean   :35720               Mean   :-163.0  \n 3rd Qu.:1   3rd Qu.:35720               3rd Qu.:-129.6  \n Max.   :1   Max.   :35720               Max.   :-110.8  \n\nllks_slice |&gt;\n  pivot_longer(c(Beta,gamma)) |&gt;\n  filter(name==slice) |&gt;\n  ggplot(aes(x=value,y=loglik,color=name))+\n  geom_point()+\n  facet_grid(~name,scales=\"free_x\")+\n  guides(color=\"none\")+\n  labs(x=\"parameter value\",color=\"\")"
  },
  {
    "objectID": "simulation.html",
    "href": "simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "Compartment model introduction\n\nSIR model, deterministic\nSIR model, stochastic\n\nModel with observations\n\nSIR model with a diagnosis compartment\n\nPartially Observed Markov Process (POMP)\n\nstate process and measurement model\nSIR model in a POMP model"
  },
  {
    "objectID": "simulation.html#summary",
    "href": "simulation.html#summary",
    "title": "Simulation",
    "section": "",
    "text": "Compartment model introduction\n\nSIR model, deterministic\nSIR model, stochastic\n\nModel with observations\n\nSIR model with a diagnosis compartment\n\nPartially Observed Markov Process (POMP)\n\nstate process and measurement model\nSIR model in a POMP model"
  },
  {
    "objectID": "simulation.html#installation-of-related-packages",
    "href": "simulation.html#installation-of-related-packages",
    "title": "Simulation",
    "section": "Installation of related packages",
    "text": "Installation of related packages\nWe will be using pomp, tidyverse, and ggplot2 across this series of sessions. For Windows users, please go to https://cran.r-project.org/bin/windows/Rtools/, download and install RTools 4.4 first. For all platform users, please install pomp by running command\ninstall.packages(\"pomp\")\nwithin RStudio Console."
  },
  {
    "objectID": "simulation.html#introduction-to-epidemiological-compartmental-models",
    "href": "simulation.html#introduction-to-epidemiological-compartmental-models",
    "title": "Simulation",
    "section": "Introduction to Epidemiological Compartmental Models",
    "text": "Introduction to Epidemiological Compartmental Models\nCompartment models, such as Susceptible-Infected-Recovered (SIR) model, divide the total population into different groups (i.e., compartments) and model the dynamics for each group by incorporating transitions between them. We can use diagrams to illustrate the model structures and the events (transitions) between compartments and formulate the dynamics using ODEs.\n\nExample: SIR model\n\n\n\nSIR model diagram. Three compartments are included in this presented SIR model, with two events: transmission (i.e. S to I) with per-capita rate \\(\\beta\\,I\\) and recovery (i.e. I to R) with per-capita rate \\(\\gamma\\).\n\n\n\\[\\begin{aligned}\n  \\frac{d S}{d t} &= -\\beta S \\frac{I}{N} \\\\\n  \\frac{d I}{d t} &= \\beta S \\frac{I}{N} - \\gamma I \\\\\n  \\frac{d R}{d t} &= \\gamma I \\\\\n  N &= S + I + R\n\\end{aligned}\\]"
  },
  {
    "objectID": "simulation.html#simulate-the-sir-model",
    "href": "simulation.html#simulate-the-sir-model",
    "title": "Simulation",
    "section": "Simulate the SIR model",
    "text": "Simulate the SIR model\n\nA deterministic model\nBased on the ODEs, we can write a function to simulate one-step-transition of the deterministic SIR model:\n\nsir_determ_step &lt;- function (S, I, R, N, Beta, gamma, delta.t, ...) {\n  dN_SI &lt;- Beta * I * S / N * delta.t\n  dN_IR &lt;- gamma * I * delta.t\n  S &lt;- S - dN_SI\n  I &lt;- I + dN_SI - dN_IR\n  R &lt;- R + dN_IR\n  return (c(S = S, I = I, R = R))\n}\n\nTo simulate the full dynamics of the proposed SIR model, we also need the initial values for \\(S\\), \\(I\\), and \\(R\\), which we denote as \\(S_0\\), \\(I_0\\), and \\(R_0\\).\n\nsir_init &lt;- function (S0, I0, R0) {\n  return(c(S = S0, I = I0, R = R0))\n}\n\nNow we can combine the initialization function and the one-step-transition function to simulate the deterministic SIR dynamics:\n\n# initialize the system\ninits &lt;- sir_init(S0=9999, I0=1, R0=0)\n# restore the results\nresults &lt;- data.frame(t = 0, S = inits[1], I = inits[2], R = inits[3])\n# the end time and time step\nt &lt;- 0\ntend &lt;- 200\ndelta.t &lt;- 1\n# parameter setting\nparams &lt;- c(Beta = 0.1, gamma = 0.01)\nwhile (t &lt; tend) {\n  t &lt;- t + delta.t\n  prev_states &lt;- results[nrow(results),]\n  current_states &lt;- sir_determ_step(\n    S = prev_states$S,\n    I = prev_states$I,\n    R = prev_states$R,\n    N = prev_states$S + prev_states$I + prev_states$R,\n    Beta = params[\"Beta\"],\n    gamma = params[\"gamma\"],\n    delta.t = delta.t\n  )\n  results &lt;- rbind(\n    results,\n    c(t = t, S = current_states[1], I = current_states[2], R = current_states[3])\n  )\n}\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\nggplot(data = results, aes(x = t)) +\n  geom_line(aes(y = S), color=\"darkgreen\") + \n  geom_line(aes(y = I), color=\"red\")+ \n  geom_line(aes(y = R), color=\"blue\") +\n  labs(x = \"time\", y = \"population\") +\n  theme_minimal() -&gt; p_determin\n\np_determin\n\n\n\n\n\n\n\n# zoom-in\np_determin +\n  coord_cartesian(xlim=c(120,130), ylim=c(6e3, 7e3))\n\n\n\n\n\n\n\n\n\n\nA stochastic model\nTo make the model more realistic, we incorporate some level of stochasticity in each transitions assuming the number of individuals in each transitions follows a binomial distribution:\n\nsir_stoch_step &lt;- function (S, I, R, N, Beta, gamma, delta.t, ...) {\n  dN_SI &lt;- rbinom(n=1, size=S, prob=1-exp(-Beta * I / N * delta.t))\n  dN_IR &lt;- rbinom(n=1, size=I, prob=1-exp(-gamma * delta.t))\n  S &lt;- S - dN_SI\n  I &lt;- I + dN_SI - dN_IR\n  R &lt;- R + dN_IR\n  return (c(S = S, I = I, R = R))\n}\n\nAgain we can simulate this stochastic SIR model:\n\n# initialize the system\ninits &lt;- sir_init(S0=9999, I0=1, R0=0)\n# restore the results\nresults &lt;- data.frame(t = 0, S = inits[1], I = inits[2], R = inits[3])\n# the end time and time step\nt &lt;- 0\ntend &lt;- 200\ndelta.t &lt;- 1\n# parameter setting\nparams &lt;- c(Beta = 0.1, gamma = 0.01)\nwhile (t &lt; tend) {\n  t &lt;- t + delta.t\n  prev_states &lt;- results[nrow(results),]\n  current_states &lt;- sir_stoch_step(\n    S = prev_states$S,\n    I = prev_states$I,\n    R = prev_states$R,\n    N = prev_states$S + prev_states$I + prev_states$R,\n    Beta = params[\"Beta\"],\n    gamma = params[\"gamma\"],\n    delta.t = delta.t\n  )\n  results &lt;- rbind(\n    results,\n    c(t = t, S = current_states[1], I = current_states[2], R = current_states[3])\n  )\n}\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nggplot(data = results, aes(x = t)) +\n  geom_line(aes(y = S), color=\"darkgreen\") + \n  geom_line(aes(y = I), color=\"red\") + \n  geom_line(aes(y = R), color=\"blue\") +\n  labs(x = \"time\", y = \"population\") +\n  theme_minimal() -&gt; p_stoch\n\np_stoch\n\n\n\n\n\n\n\np_stoch +\n  coord_cartesian(xlim=c(120,130), ylim=c(6e3, 7e3))\n\n\n\n\n\n\n\n\n\n\nTry some other models?"
  },
  {
    "objectID": "simulation.html#sir-model-observations",
    "href": "simulation.html#sir-model-observations",
    "title": "Simulation",
    "section": "SIR model + observations",
    "text": "SIR model + observations\nUnfortunately, we don’t observed all states (\\(S\\), \\(I\\), and \\(R\\)).\n\nSIR model with a diagnosis compartment\nWe assume that the infections (i.e. patients) go to the hospitial and get diagnosed and denote this new compartment as \\(D\\):\n\n\n\nSIR + Diagnosis model diagram.\n\n\n\\[\\begin{aligned}\n  \\frac{d S}{d t} &= -\\beta S \\frac{I}{N} \\\\\n  \\frac{d I}{d t} &= \\beta S \\frac{I}{N} - \\gamma I \\\\\n  \\frac{d R}{d t} &= \\gamma I \\\\\n  \\frac{d D}{d t} &= \\gamma I \\\\\n  N &= S + I + R\n\\end{aligned}\\]\nNow we define a new one-step-transition function:\n\nsird_stoch_step &lt;- function (S, I, R, N, D, Beta, gamma, delta.t, ...) {\n  dN_SI &lt;- rbinom(n=1, size=S, prob=1-exp(-Beta * I / N * delta.t))\n  dN_IR &lt;- rbinom(n=1, size=I, prob=1-exp(-gamma * delta.t))\n  S &lt;- S - dN_SI\n  I &lt;- I + dN_SI - dN_IR\n  R &lt;- R + dN_IR\n  D &lt;- D + dN_IR\n  return (c(S = S, I = I, R = R, D = D))\n}\n\nwith the new initialization function:\n\nsird_init &lt;- function (S0, I0, R0, D0=0) {\n  return(c(S = S0, I = I0, R = R0, D = D0))\n}"
  },
  {
    "objectID": "simulation.html#partially-observed-markov-process-pomp",
    "href": "simulation.html#partially-observed-markov-process-pomp",
    "title": "Simulation",
    "section": "Partially Observed Markov Process (POMP)",
    "text": "Partially Observed Markov Process (POMP)\nWhat’s worse, we cannot even observe the true values of any state. We only have partial observations within a period of time, let’s say, 7 days.\n\nState process and measurement model\nIn the POMP model, we have two main components: the underlying state process and measurement model to the observations.\n\n\n\nPOMP structure.\n\n\nLet’s break it into details, defining the underlying state process as \\(X_t\\) and the observed measurements as \\(Y_t\\), both of which are markovian.\n\n\n\nPOMP schematic.\n\n\n\n\nSIR model in a POMP model\nNow we can define the state process as a stochastic SIR model, \\(X_t = (S_t, I_t, R_t, D_t)\\), where we call \\(D_t\\) as the weekly cumulative diagnoses, which resets to 0 every 7 days.\nWe further can define a weekly measurement model: \\[\n\\textrm{reports}_t \\sim \\textrm{NegBin}(\\rho D_t, k),\n\\] where \\(\\rho\\) is the reporting ratio and \\(k\\) is the dispersion parameter in the Negative Binomial distribution. Of course, we can also define the measurement model as a Binomial distribution or Poisson distribution.\nUsing this measurement model, we can have the probability a case report given the true diagnoses, as well as simulate the reported cases based on the SIR with diagnosis model:\n\n## density/probability\nsird_dmeas &lt;- function (reports, D, rho, k, log, ...) {\n  dnbinom(x=reports, size=k, mu=rho*D, log=log)\n}\n\n## simulation\nsird_rmeas &lt;- function (D, rho, k, ...) {\n  return (c(reports=rnbinom(n=1, size=k, mu=rho*D)))\n}\n\nWe can update the one-step transition function:\n\nsird_stoch_pomp_step &lt;- function (S, I, R, N, D, Beta, gamma, t, delta.t, cum_step, ...) {\n  dN_SI &lt;- rbinom(n=1, size=S, prob=1-exp(-Beta * I / N * delta.t))\n  dN_IR &lt;- rbinom(n=1, size=I, prob=1-exp(-gamma * delta.t))\n  S &lt;- S - dN_SI\n  I &lt;- I + dN_SI - dN_IR\n  R &lt;- R + dN_IR\n  if (t %% cum_step == 1)  D &lt;- 0\n  D &lt;- D + dN_IR\n  return (c(S = S, I = I, R = R, D = D))\n}\n\nNow we can simulate the underlying SIRD models and the reported cases:\n\n# initialize the system\ninits &lt;- sird_init(S0=9999, I0=1, R0=0, D0=0)\n# restore the results\nresults &lt;- data.frame(t = 0, S = inits[1], I = inits[2], R = inits[3], D = inits[4], reports = 0)\n# the end time and time steps\nt &lt;- 0\ntend &lt;- 200\ndelta.t &lt;- 1\ncum_step &lt;- 7\n# parameter setting\nparams &lt;- c(Beta = 0.1, gamma = 0.01, rho=0.2, k=3)\nwhile (t &lt; tend) {\n  t &lt;- t + delta.t\n  prev_states &lt;- results[nrow(results),]\n  current_states &lt;- sird_stoch_pomp_step(\n    S = prev_states$S,\n    I = prev_states$I,\n    R = prev_states$R,\n    N = prev_states$S + prev_states$I + prev_states$R,\n    D = prev_states$D, \n    Beta = params[\"Beta\"],\n    gamma = params[\"gamma\"],\n    t = t,\n    delta.t = delta.t,\n    cum_step = cum_step\n  )\n  reports &lt;- 0\n  if (t %% cum_step == 0)\n    reports &lt;- sird_rmeas(D = current_states[4], rho = params[\"rho\"], k = params[\"k\"])\n  results &lt;- rbind(\n    results,\n    c(t = t, S = current_states[1], I = current_states[2], R = current_states[3], D = current_states[4], reports = reports[1])\n  )\n}\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nggplot(data = results, aes(x = t)) +\n  geom_line(aes(y = S), color=\"darkgreen\") + \n  geom_line(aes(y = I), color=\"red\") + \n  geom_line(aes(y = R), color=\"blue\") +\n  geom_line(aes(y = D), color=\"grey\") +\n  geom_step(aes(y = reports), color=\"black\") +\n  labs(x = \"time\", y = \"population\") +\n  scale_y_log10() +\n  theme_minimal() -&gt; p_stoch_pomp\n\np_stoch_pomp\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simulation-based Inference for Epidemiological Dynamics",
    "section": "",
    "text": "This module introduces statistical inference techniques and computational methods for dynamic models of epidemiological systems. The course will explore deterministic and stochastic formulations of epidemiological dynamics and develop inference methods appropriate for a range of models. Special emphasis will be on exact and approximate likelihood as the key elements in parameter estimation, hypothesis testing, and model selection. Specifically, the course will cover sequential Monte Carlo and synthetic likelihood techniques. Students will learn to implement these in R to carry out maximum likelihood and Bayesian inference. Knowledge of the material in Module 1 is assumed. Students new to R should complete a tutorial before the module."
  },
  {
    "objectID": "index.html#module-description",
    "href": "index.html#module-description",
    "title": "Simulation-based Inference for Epidemiological Dynamics",
    "section": "",
    "text": "This module introduces statistical inference techniques and computational methods for dynamic models of epidemiological systems. The course will explore deterministic and stochastic formulations of epidemiological dynamics and develop inference methods appropriate for a range of models. Special emphasis will be on exact and approximate likelihood as the key elements in parameter estimation, hypothesis testing, and model selection. Specifically, the course will cover sequential Monte Carlo and synthetic likelihood techniques. Students will learn to implement these in R to carry out maximum likelihood and Bayesian inference. Knowledge of the material in Module 1 is assumed. Students new to R should complete a tutorial before the module."
  },
  {
    "objectID": "index.html#course-objectives",
    "href": "index.html#course-objectives",
    "title": "Simulation-based Inference for Epidemiological Dynamics",
    "section": "Course objectives",
    "text": "Course objectives\n\nTo introduce partially observed Markov process (POMP) models as tools for scientific investigation and public health policy.\nTo give students the ability to formulate POMP models of their own.\nTo teach efficient approaches for performing scientific inference using POMP models.\nTo familiarize students with the pomp package.\nTo give students opportunities to work with such inference methods.\nTo provide documented examples for student re-use."
  },
  {
    "objectID": "index.html#lessons",
    "href": "index.html#lessons",
    "title": "Simulation-based Inference for Epidemiological Dynamics",
    "section": "Lessons",
    "text": "Lessons\n\nInstructions for preparing your laptop for the course exercises.\nIntroduction: What is “Simulation-based Inference for Epidemiological Dynamics”? POMPs and pomp.\nSimulation of stochastic dynamic models.\nLikelihood for POMPs: theory and practice.\nIterated filtering: theory and practice.\nCase study: measles. Recurrent epidemics, long time series, covariates, extra-demographic stochasticity, interpretation of parameter estimates.\nCase study: polio. Workflow for a real research problem.\nCase study: Ebola. Model diagnostics and forecasting.\nCase study: HIV and fluctuating sexual contact rates. Panel data."
  },
  {
    "objectID": "index.html#credits",
    "href": "index.html#credits",
    "title": "Simulation-based Inference for Epidemiological Dynamics",
    "section": "Credits",
    "text": "Credits\nThis website and all the materials are adapted from https://kingaa.github.io/sbied/. We would like send our sincere gratitude to Professors Aaron A. King and Edward L. Ionides for creating this wonderful course and for helping us developing our own version."
  }
]